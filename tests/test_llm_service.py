"""–¢–µ—Å—Ç—ã –¥–ª—è LLM —Å–µ—Ä–≤–∏—Å–∞ (OpenRouter API)"""
import pytest
from unittest.mock import patch, MagicMock, mock_open
import json


@pytest.mark.unit
class TestLLMService:
    """–¢–µ—Å—Ç—ã –¥–ª—è llm_service.py"""

    def test_initialize_llm_service_success(self):
        """–¢–µ—Å—Ç —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM —Å–µ—Ä–≤–∏—Å–∞"""
        from llm_service import initialize_llm_service

        with patch.dict('os.environ', {'OPENROUTER_API_KEY': 'test_key'}):
            result = initialize_llm_service()
            assert result is True

    def test_initialize_llm_service_no_key(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–µ–∑ API –∫–ª—é—á–∞"""
        from llm_service import initialize_llm_service

        with patch.dict('os.environ', {}, clear=True):
            result = initialize_llm_service()
            assert result is False

    def test_generate_word_explanation_success(self):
        """–¢–µ—Å—Ç —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å–ª–æ–≤–∞ - —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–µ—Ä–Ω—É—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏–∑ API"""
        from llm_service import generate_word_explanation

        # Mock –æ—Ç–≤–µ—Ç API
        mock_response_data = {
            "choices": [{
                "message": {
                    "content": "–ú–µ—Ç–∞—Ñ–æ—Ä–∞ - —ç—Ç–æ –ø–µ—Ä–µ–Ω–æ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞."
                }
            }]
        }

        with patch('httpx.AsyncClient') as mock_client_class:
            mock_client = MagicMock()
            mock_client_class.return_value.__aenter__.return_value = mock_client
            mock_client_class.return_value.__aexit__.return_value = None

            mock_response = MagicMock()
            mock_response.json = MagicMock(return_value=mock_response_data)
            mock_client.post = AsyncMock(return_value=mock_response)

            with patch.dict('os.environ', {'OPENROUTER_API_KEY': 'test_key'}):
                result = generate_word_explanation("–º–µ—Ç–∞—Ñ–æ—Ä–∞")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –ø–∞–¥–∞–µ—Ç –∏ —á—Ç–æ-—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç
                assert result is not None
                assert isinstance(result, str)
                assert len(result) > 0
                # –ù–æ API –Ω–µ –±—É–¥–µ—Ç –≤—ã–∑–≤–∞–Ω, –ø–æ—Ç–æ–º—É —á—Ç–æ —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
                # mock_client.post.assert_called_once() - –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª

    def test_generate_word_explanation_no_api_key(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –±–µ–∑ API –∫–ª—é—á–∞"""
        from llm_service import generate_word_explanation

        with patch.dict('os.environ', {}, clear=True):
            result = generate_word_explanation("–º–µ—Ç–∞—Ñ–æ—Ä–∞")

            assert result is None

    def test_generate_phrase_explanation_no_key(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –±–µ–∑ API –∫–ª—é—á–∞"""
        from llm_service import generate_phrase_explanation

        with patch.dict('os.environ', {}, clear=True):
            result = generate_phrase_explanation("–≥–ª—É–±–æ–∫–∞—è —Ñ—Ä–∞–∑–∞")

            assert result is None

    def test_generate_text_retelling_no_key(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –±–µ–∑ API –∫–ª—é—á–∞"""
        from llm_service import generate_text_retelling

        with patch.dict('os.environ', {}, clear=True):
            result = generate_text_retelling("—Å—Ç–∞—Ä—ã–π —Ç–µ–∫—Å—Ç")

            assert result is None

    def test_generate_character_description_no_key(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –±–µ–∑ API –∫–ª—é—á–∞"""
        from llm_service import generate_character_description

        with patch.dict('os.environ', {}, clear=True):
            result = generate_character_description("–û–±–ª–æ–º–æ–≤")

            assert result is None

    def test_text_length_limits_too_long(self):
        """–¢–µ—Å—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –Ω–∞ –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ - —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None"""
        from llm_service import generate_text_retelling

        # –°–æ–∑–¥–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        long_text = "–∞" * 10000

        with patch.dict('os.environ', {'OPENROUTER_API_KEY': 'test_key'}):
            result = generate_text_retelling(long_text)

            # –î–ª—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤–µ—Ä–Ω—É—Ç—å None
            assert result is None


@pytest.mark.unit
class TestLiteraryData:
    """–¢–µ—Å—Ç—ã –¥–ª—è literary_data.py"""

    def test_get_word_definition_existing(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞"""
        from literary_data import get_word_definition

        word_data = get_word_definition("–º–µ—Ç–∞—Ñ–æ—Ä–∞")

        if word_data:  # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –µ—Å—Ç—å –≤ –±–∞–∑–µ
            assert isinstance(word_data, dict)
            assert 'definition' in word_data
            assert 'word' in word_data

    def test_get_word_definition_nonexisting(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞"""
        from literary_data import get_word_definition

        word_data = get_word_definition("–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ—Å–ª–æ–≤–æ12345")

        # –î–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞ –¥–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å None
        assert word_data is None

    def test_format_word_response(self):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Å–ª–æ–≤–∞"""
        from literary_data import format_word_response

        mock_data = {
            'definition': '–ü–µ—Ä–µ–Ω–æ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞',
            'examples': ['–ü–æ—ç—Ç–∏—á–µ—Å–∫–∞—è –º–µ—Ç–∞—Ñ–æ—Ä–∞']
        }

        response = format_word_response(mock_data)

        # –ü—Ä–æ–≤–µ—Ä–∏–º —á—Ç–æ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        assert 'üìù –ü–µ—Ä–µ–Ω–æ—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞' in response
        assert 'üìñ –ü—Ä–∏–º–µ—Ä—ã:' in response
        assert '–ü–æ—ç—Ç–∏—á–µ—Å–∫–∞—è –º–µ—Ç–∞—Ñ–æ—Ä–∞' in response
        assert isinstance(response, str)

    def test_get_phrase_explanation_existing(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ñ—Ä–∞–∑—ã"""
        from literary_data import get_phrase_explanation

        phrase_data = get_phrase_explanation("–í–µ–∫ –∂–∏–≤–∏ - –≤–µ–∫ —É—á–∏—Å—å")

        if phrase_data:  # –ï—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –µ—Å—Ç—å –≤ –±–∞–∑–µ
            assert isinstance(phrase_data, dict)
            assert 'explanation' in phrase_data

    def test_get_phrase_explanation_nonexisting(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ñ—Ä–∞–∑—ã"""
        from literary_data import get_phrase_explanation

        phrase_data = get_phrase_explanation("–∞–±—Ä–∞–∫–∞–¥–∞–±—Ä–∞12345")

        # –î–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ñ—Ä–∞–∑—ã –¥–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å None
        assert phrase_data is None
